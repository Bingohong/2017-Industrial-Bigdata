{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.训练数据集处理\n",
    "- 训练集train_15和trian_21\n",
    "- 根据故障时间为训练集设定标签\n",
    "- 结冰为1，无结冰为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy.stats import norm \n",
    "from scipy import stats\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "path=r\"F:\\Diverse\\statistics\\Python_data_analysis\\首届（2017）中国工业大数据创新竞赛\\叶片结冰预测\"\n",
    "os.chdir(path)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入数据集\n",
    "train_15=pd.read_csv(r\"train\\15\\15_data.csv\")\n",
    "train_21=pd.read_csv(r\"train\\21\\21_data.csv\")\n",
    "print(\"train_15.shape: \",train_15.shape,\"train_21.shape: \",train_21.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入故障时间\n",
    "failureInfo_15=pd.read_csv(r\"train\\15\\15_failureInfo.csv\")\n",
    "normalInfo_15=pd.read_csv(r\"train/15/15_normalInfo.csv\")\n",
    "failureInfo_21=pd.read_csv(r\"train\\21\\21_failureInfo.csv\")\n",
    "normalInfo_21=pd.read_csv(r\"train/21/21_normalInfo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#风机状态标签函数\n",
    "def filter_state(train=train_15,failureInfo=failureInfo_15,normalInfo=normalInfo_15):\n",
    "    #将时间转换为时间序列,时间戳\\\n",
    "    #建立记录事故情况序列，索引为时间戳\n",
    "    data=np.ones([train.shape[0],1])*np.nan\n",
    "    time=pd.DataFrame(data,index=pd.to_datetime(train.time),columns=[\"state\"])\n",
    "    \n",
    "    #将事故时间段转化为时间戳\n",
    "    for k in failureInfo.columns:\n",
    "        failureInfo[k]=pd.to_datetime(failureInfo[k])\n",
    "        normalInfo[k]=pd.to_datetime(normalInfo[k])\n",
    "    \n",
    "    #运行状况标记\n",
    "    #Dataframe可以使用时间戳切片，不可以直接使用时间戳进行索引\n",
    "    for i in failureInfo.index:\n",
    "        time[failureInfo.iloc[i,0]:failureInfo.iloc[i,1]]=1\n",
    "    for j in normalInfo.index:\n",
    "        time[normalInfo.iloc[j,0]:normalInfo.iloc[j,1]]=0\n",
    "               \n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#风机状态设定\n",
    "time_15=filter_state(train_15,failureInfo_15,normalInfo_15)\n",
    "time_21=filter_state(train_21,failureInfo_21,normalInfo_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#数据拼接函数\n",
    "def data_merge(train,time):\n",
    "    train.time=pd.to_datetime(train.time)\n",
    "    data=pd.merge(train,time,left_on=\"time\",right_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_15=data_merge(train_15,time_15)\n",
    "data_21=data_merge(train_21,time_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#特征预处理函数\n",
    "def filter_data(train=train_15):\n",
    "    #将成组的变量转化为均值，约简为该属性的特征\n",
    "    train[\"pitch_angle\"]=train[[\"pitch1_angle\",\"pitch2_angle\",\"pitch3_angle\"]].T.mean()\n",
    "    train[\"pitch_speed\"]=train[[\"pitch1_speed\",\"pitch2_speed\",\"pitch3_speed\"]].T.mean()\n",
    "    train[\"pitch_moto_tmp\"]=train[[\"pitch1_moto_tmp\",\"pitch2_moto_tmp\",\"pitch3_moto_tmp\"]].T.mean()\n",
    "    train[\"pitch_ng5_tmp\"]=train[[\"pitch1_ng5_tmp\",\"pitch2_ng5_tmp\",\"pitch3_ng5_tmp\"]].T.mean()\n",
    "    train[\"pitch_ng5_DC\"]=train[[\"pitch1_ng5_DC\",\"pitch2_ng5_DC\",\"pitch3_ng5_DC\"]].T.mean()\n",
    "    train[\"acc\"]=np.sqrt((train.acc_x.values)**2+(train.acc_y.values)**2)\n",
    "    #丢弃多余特征\n",
    "    train=train.drop([\"pitch1_angle\",\"pitch2_angle\",\"pitch3_angle\",\"pitch1_speed\",\"pitch2_speed\",\"pitch3_speed\",\"pitch1_moto_tmp\",\"pitch2_moto_tmp\",\"pitch3_moto_tmp\",\"pitch1_ng5_tmp\",\"pitch2_ng5_tmp\",\"pitch3_ng5_tmp\",\"pitch1_ng5_DC\",\"pitch2_ng5_DC\",\"pitch3_ng5_DC\"],axis=1)\n",
    "    train=train.drop([\"time\",\"acc_x\",\"acc_y\"],axis=1)\n",
    "    #生成新特征\n",
    "    #考虑偏航系统对风角跟风向角有关，做差\n",
    "    #考虑环境温度与机舱温度差\n",
    "    #偏航速度受偏航系统限制，变化不大，舍弃\n",
    "    train[\"difference_tmp\"]=train.int_tmp-train.environment_tmp\n",
    "    train[\"difference_wind_direction\"]=train.wind_direction_mean-train.wind_direction\n",
    "    train.drop([\"yaw_speed\",\"int_tmp\",\"environment_tmp\",\"wind_direction_mean\",\"wind_direction\"],axis=1,inplace=True)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#特征处理\n",
    "data_15=filter_data(train=data_15)\n",
    "data_21=filter_data(train=data_21)\n",
    "data=pd.concat([data_15,data_21],axis=0)\n",
    "data.dropna(inplace=True)\n",
    "data.iloc[:,:-1].to_csv(r\"train\\train.csv\",index=False)\n",
    "data.iloc[:,-1].to_csv(r\"train\\results.csv\",index=False)\n",
    "\n",
    "print(\"data-state: \",data.groupby(\"state\").size(),\"data.shape: \",data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.特征工程\n",
    "- 生成特征多项式\n",
    "- 根据filter、embedded和wrapper方法筛选特征\n",
    "- 统计各种方法出现的特征情况，依据频数选取特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(r\"train\\train.csv\")\n",
    "results=pd.read_csv(r\"train\\results.csv\")\n",
    "train.drop([\"pitch_speed\",\"acc\",\"pitch_ng5_DC\"],axis=1,inplace=True)\n",
    "print(results.groupby(\"state\").size())\n",
    "x=train.copy()\n",
    "y=results.values.copy()\n",
    "sample=x.copy()\n",
    "sample[\"state\"]=y\n",
    "print(sample.shape,\"\\n\",sample.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2简单随机抽样,减少计算时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "sample1=sample[sample.state==0].sample(frac=0.06650808*0.75)\n",
    "sample2=sample[sample.state==1].sample(frac=0.75)\n",
    "\n",
    "data=pd.concat([sample1,sample2],ignore_index=True)\n",
    "x_resample,y_resample=data.iloc[:,:-1],data.state.values\n",
    "x_resample,y_resample=shuffle(x_resample,y_resample)\n",
    "\n",
    "print(sample.shape,\"\\n\",x_resample.shape,\"\\n\",y_resample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3创造多项式特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "def polyfeature(x_resample):    \n",
    "    x_resample_poly=PolynomialFeatures().fit_transform(x_resample)\n",
    "    poly_feature=PolynomialFeatures().fit(x_resample).get_feature_names(input_features=x_resample.columns)\n",
    "    x_resample_poly=pd.DataFrame(x_resample_poly,columns=poly_feature)\n",
    "    return x_resample_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_resample_poly=polyfeature(x_resample)\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_resample_poly,y_resample,random_state=42)\n",
    "ratio=(np.count_nonzero(y_train==1)/np.count_nonzero(y_train==0))\n",
    "\n",
    "print(X_train.shape,\"\\n\",ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1) filter-过滤法，按照发散性或相关性，1.f_score得分\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "f_test=SelectKBest(k=10).fit(X_train,y_train)\n",
    "f_index=X_train.columns[np.argsort(-f_test.scores_)]\n",
    "print(np.argsort(-f_test.scores_),\"\\n\",f_index[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2) wrapper-封装式，递归特征消除法-recursive-feature-elimination\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "estimator=GradientBoostingClassifier(\n",
    "    learning_rate=0.0001,\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    subsample=0.5,\n",
    "    max_features=0.7\n",
    "    )\n",
    "rfe_gbc=RFECV(estimator,cv=3,scoring=\"precision\").fit(X_train,y_train.ravel())\n",
    "\n",
    "rfe_index=X_train.columns[np.argsort(-rfe_gbc.grid_scores_)]\n",
    "print(rfe_gbc.support_,\"\\n\",rfe_index[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3.1) 特征选择方法，embedded--嵌入式，GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "estimator=GradientBoostingClassifier(\n",
    "    learning_rate=0.0001,\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    subsample=0.5,\n",
    "    max_features=0.7\n",
    "    )\n",
    "emb_gbc=SelectFromModel(estimator).fit(X_train,y_train.ravel())\n",
    "emb_gb_index=X_train.columns[emb_gbc.get_support()]\n",
    "print(emb_gbc.get_support(),\"\\n\",emb_gb_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3.2) 特征选择方法，embedded--嵌入式，RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator=RandomForestClassifier(\n",
    "    #learning_rate=0.0001,\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    #subsample=0.5,\n",
    "    max_features=0.7\n",
    "    )\n",
    "\n",
    "emb_rfc=SelectFromModel(estimator).fit(X_train,y_train.ravel())\n",
    "emb_rfc_index=X_train.columns[emb_rfc.get_support()]\n",
    "print(emb_rfc.get_support(),\"\\n\",emb_rfc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3.3) 特征选择方法，embedded--嵌入式，XGBoost\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_final = xgb.XGBClassifier( \n",
    "    learning_rate =0.0001, \n",
    "    n_estimators=100,\n",
    "    max_depth=5, \n",
    "    min_child_weight=1,\n",
    "    gamma=0.2,\n",
    "    subsample=0.5,\n",
    "    colsample_bytree=0.7,\n",
    "    reg_alpha=120,\n",
    "    reg_lambda=10,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4, \n",
    "    scale_pos_weight=ratio*0.8,\n",
    "    seed=27)\n",
    "\n",
    "emb_xgb=SelectFromModel(xgb_final).fit(X_train,y_train.ravel())\n",
    "emb_xgb_index=X_train.columns[emb_xgb.get_support()]\n",
    "print(emb_xgb.get_support(),\"\\n\",emb_xgb_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4) 统计特征出现次数\n",
    "feature_index=np.hstack((rfe_index[:20].values,emb_rfc_index.values,emb_gb_index.values,emb_xgb_index.values))\n",
    "f=pd.DataFrame(feature_index,columns=[\"f_index\"])\n",
    "feature_rank=f.apply(pd.value_counts)\n",
    "\n",
    "feature_rank.to_csv(\"feature_rank.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.特征数据集\n",
    "- 根据特征出现频数选择特征\n",
    "- 定义数据集处理函数\n",
    "- 生成多项式数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1) 根据需求调整特征\n",
    "feature_rank=pd.read_csv(\"feature_rank.csv\",index_col=0)\n",
    "feature=feature_rank[feature_rank.f_index>=3].index\n",
    "print(\"Features: \",feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2) 定义数据集处理函数，将原始数据集转化为多项式数据集，便于直接使用\n",
    "def polydataset(dataname=r\"train\\train.csv\",resultname=r\"train_15_results.csv\",feature=feature,outputfilename=r\"train_ensemble.csv\"):\n",
    "    data=pd.read_csv(dataname)\n",
    "    results=pd.read_csv(resultname)\n",
    "    data.drop([\"pitch_speed\",\"acc\",\"pitch_ng5_DC\"],axis=1,inplace=True)\n",
    "    data=polyfeature(data)[feature]\n",
    "    print(\"data: \",data.shape,results.shape)\n",
    "    \n",
    "    ee=EasyEnsemble()\n",
    "    x_rem,y_rem=ee.fit_sample(data,results)\n",
    "    print(\"x_rem: \",x_rem.shape)\n",
    "    \n",
    "    draw=pd.DataFrame(x_rem[0],columns=feature)\n",
    "    draw[\"results\"]=y_rem[0]\n",
    "    draw.to_csv(outputfilename,index=False)\n",
    "    print(\"drawdata: \",draw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3) 数据集整理\n",
    "#train_15数据集\n",
    "polydataset(dataname=r\"train\\train_15.csv\",resultname=r\"train\\train_15_results.csv\",feature=feature,outputfilename=r\"train_15_ensemble.csv\")\n",
    "\n",
    "#train_21数据集\n",
    "polydataset(dataname=r\"train\\train_21.csv\",resultname=r\"train\\train_21_results.csv\",feature=feature,outputfilename=r\"train_21_ensemble.csv\")\n",
    "\n",
    "#train_21+train_15混合数据集\n",
    "polydataset(dataname=r\"train\\train.csv\",resultname=r\"train\\results.csv\",feature=feature,outputfilename=r\"train_ensemble.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
